{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de PARCTICAS AVANZADAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMBdGAARy+mG8UtSxOw+aqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniela2001-png/DATA_SCIENCE/blob/master/Copia_de_PARCTICAS_AVANZADAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0kVZXmxoPmb",
        "outputId": "a94caf9d-1150-4f59-b4f1-62efba0d0e4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9CAO0ZVo1WS"
      },
      "source": [
        "filepath = '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcmvWlJgo6zr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lim0uXCVo9gn"
      },
      "source": [
        "# ***CONSTRUYENDO CODIGO ESTRUCTURADO CON FUNCIONES***\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRtkdUzWpJkm"
      },
      "source": [
        "ejemplo 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khwc9Er-pLoX"
      },
      "source": [
        "import re\n",
        "def get_text(file):\n",
        "    # por alguna razon que no entiendo con with open a la hora abrirlo no lo esta leyendo bien asi que use este open\n",
        "    text = open(file).read()\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddZUt4c0qtj-",
        "outputId": "72da420b-e1ca-49ce-acbf-ef79d2493019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "get_text(filepath+\"texto.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tipos de textos Un texto informativo: es aquel que tiene la atención de informar, es objetivo, da los hechos: que pasó, quienes intervinieron, donde, cuándo, sin recursos estilísticos. Es el usado en diarios serios por ejemplo. Usa el verbo en Modo Indicativo. El texto expresivo: es subjetivo, usa recursos de estilo y su intención no es informar sino transmitir sentimientos, belleza, etc. Usa cualquier modo del verbo, y signos de entonación. Un texto apelativo: es el que convence, sugiere, ruega, aconseja, es el lenguaje de la propaganda por ejemplo o de las recetas de cocina. Usa el verbo en condicional o imperativo. Texto Argumentativo: un escrito que defiende una opinión (tesis) y que quiere persuadir de ella a un receptor mediante pruebas y razonamientos. Está en relación con: “la lógica (leyes del razonamiento humano), la dialéctica (procedimientos que se ponen en juego para probar o refutar algo) y la retórica (uso de recursos lingüísticos con el fin de persuadir movilizando resortes no racionales, como son los efectos, las emociones, las sugestiones…).” (Variedades discursivas: La argumentación). Texto lingüístico: de acuerdo a Greimas, es un enunciado ya sea gráfico o fónico que nos permite visualizar las palabras que escuchamos que es utilizado para manifestar el proceso lingüístico. Mientras Hjelmslev usa ese término para designar el todo de una cadena lingüística ilimitada. En lingüística no todo conjunto de signos constituye un texto. Se le llama texto a la configuración de lengua o habla y se utilizan signos específicos (signo de la lengua o habla) y está organizada según reglas del habla o idioma.* Texto como \"diálogo\" y texto como \"monólogo\": otra noción importante es que los \"textos´\" (y discursos) no son sólo \"monologales\". En lingüística, el término texto sirve tanto para producciones en que sólo hay un emisor (situaciones monogestionadas o monocontroladas) como en las que varios intercambian sus papeles (situaciones poligestionadas o policontroladas) como las gafo conversaciones.El texto contiene conectores y signos etc. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts-OLrrXse3E"
      },
      "source": [
        "# ahora crearemos un archivo con la magia de python en nuestro drive :3\n",
        "!touch /content/drive/My\\ Drive/Colab\\ Notebooks/read.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cSRCYCDuWHp",
        "outputId": "732698fb-b008-4e3d-b09e-1bb6764a30a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ahora empezamos  acrear nuestra \"libreria\" para llmara ala unica funcion que hemos creado get_text()\n",
        "import sys\n",
        "# agregamos nuestro path de google colab al kernel de la instancia :3\n",
        "sys.path.append(filepath)\n",
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/My Drive/Colab Notebooks/',\n",
              " '/content/drive/My Drive/Colab Notebooks/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyaDTC_QvGol",
        "outputId": "0ecf60cc-b2b3-4952-db27-0a50ec2e223b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "# ahora comprobamos que el kernel de python ya entinde que dentro de sus libreraias estar nuestro modulo read.py y podremos usar nuestra funcion get_text() y todo esto en solo 2 lineas de codigo\n",
        "import read\n",
        "read.get_text(filepath+\"texto.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tipos de textos Un texto informativo: es aquel que tiene la atención de informar, es objetivo, da los hechos: que pasó, quienes intervinieron, donde, cuándo, sin recursos estilísticos. Es el usado en diarios serios por ejemplo. Usa el verbo en Modo Indicativo. El texto expresivo: es subjetivo, usa recursos de estilo y su intención no es informar sino transmitir sentimientos, belleza, etc. Usa cualquier modo del verbo, y signos de entonación. Un texto apelativo: es el que convence, sugiere, ruega, aconseja, es el lenguaje de la propaganda por ejemplo o de las recetas de cocina. Usa el verbo en condicional o imperativo. Texto Argumentativo: un escrito que defiende una opinión (tesis) y que quiere persuadir de ella a un receptor mediante pruebas y razonamientos. Está en relación con: “la lógica (leyes del razonamiento humano), la dialéctica (procedimientos que se ponen en juego para probar o refutar algo) y la retórica (uso de recursos lingüísticos con el fin de persuadir movilizando resortes no racionales, como son los efectos, las emociones, las sugestiones…).” (Variedades discursivas: La argumentación). Texto lingüístico: de acuerdo a Greimas, es un enunciado ya sea gráfico o fónico que nos permite visualizar las palabras que escuchamos que es utilizado para manifestar el proceso lingüístico. Mientras Hjelmslev usa ese término para designar el todo de una cadena lingüística ilimitada. En lingüística no todo conjunto de signos constituye un texto. Se le llama texto a la configuración de lengua o habla y se utilizan signos específicos (signo de la lengua o habla) y está organizada según reglas del habla o idioma.* Texto como \"diálogo\" y texto como \"monólogo\": otra noción importante es que los \"textos´\" (y discursos) no son sólo \"monologales\". En lingüística, el término texto sirve tanto para producciones en que sólo hay un emisor (situaciones monogestionadas o monocontroladas) como en las que varios intercambian sus papeles (situaciones poligestionadas o policontroladas) como las gafo conversaciones.El texto contiene conectores y signos etc. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kl5m2EfwYoK"
      },
      "source": [
        "# EJEMPLO 2\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmu4KxdDwcJ5"
      },
      "source": [
        "filepath_2 = \"/content/drive/My Drive/Colab Notebooks/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jysBi43wwsgC",
        "outputId": "dfe8c843-8e73-407a-8ea4-1b17e501a87a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ahora creamos nuestra funcion que toma un url y n donde n es el numero de palabras o tokens de ese texto url\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from urllib import request\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "\n",
        "def freq_words(url, n, encoding = 'utf8'):\n",
        "  req = request.urlopen(url)\n",
        "  html = req.read().decode(encoding)\n",
        "  raw = BeautifulSoup(html, 'html.parser')\n",
        "  text = raw.get_text()\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [t.lower() for t in tokens]\n",
        "  stop_words = stopwords.words('spanish')\n",
        "  tokens = [token for token in tokens if token not in stop_words]\n",
        "  fd = nltk.FreqDist(tokens)\n",
        "  return [t for (t, _) in fd.most_common(n)]\n",
        "\n",
        "\n",
        "\n",
        "freq_words('https://www.gutenberg.org/files/2701/2701-h/2701-h.htm', 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',',\n",
              " 'the',\n",
              " '.',\n",
              " 'of',\n",
              " 'and',\n",
              " 'to',\n",
              " ';',\n",
              " 'in',\n",
              " 'that',\n",
              " '’',\n",
              " 'his',\n",
              " 'it',\n",
              " 'i',\n",
              " 's',\n",
              " 'but',\n",
              " '!',\n",
              " 'with',\n",
              " 'is',\n",
              " 'as',\n",
              " 'was']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZQ4tw77yPSH"
      },
      "source": [
        "!touch /content/drive/My\\ Drive/Colab\\ Notebooks/dani_freq.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAGVBeZyc31",
        "outputId": "aaa16499-dec3-4a37-a22d-afef6b3d1aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import dani_freq\n",
        "dani_freq.freq_words('https://www.gutenberg.org/files/2701/2701-h/2701-h.htm', 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',',\n",
              " 'the',\n",
              " '.',\n",
              " 'of',\n",
              " 'and',\n",
              " 'to',\n",
              " ';',\n",
              " 'in',\n",
              " 'that',\n",
              " '’',\n",
              " 'his',\n",
              " 'it',\n",
              " 'i',\n",
              " 's',\n",
              " 'but',\n",
              " '!',\n",
              " 'with',\n",
              " 'is',\n",
              " 'as',\n",
              " 'was']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}